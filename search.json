[{"title":"Python_basics","url":"/article/Python-basics.html"},{"title":"Python 简介","url":"/article/Python-introduction.html","content":"\n\n# 1. Python 起源\n\n## 1.1 解释器\n\n**计算机不能直接理解任何除机器语言以外的语言**，所以必须要把程序员所写的程序语言翻译成机器语言，计算机才能执行程序。**将其他语言翻译成机器语言的工具，被称为编译器**。  \n编译器翻译的方式有两种：一个是**编译**，另外一个是**解释**。两种方式之间的区别在于**翻译时间点的不同**。当编译器**以解释方式运行的时候**，也称之为**解释器**。  \n![](Python-introduction/编译型和解释型语言工作对比.png)  \n\n- **编译型语言**：程序在执行之前需要一个专门的编译过程，把程序编译成为机器语言的文件，运行时不需要重新翻译，直接使用编译的结果就行了。程序执行效率高，依赖编译器，跨平台性差些。如 C、C++。  \n- **解释型语言**：解释型语言编写的程序不进行预先编译，以文本方式存储程序代码，会将代码一句一句直接运行。在发布程序时，看起来省了道编译工序，但是在运行程序的时候，必须先解释再运行。  \n\n## 1.2 Python 特点\n\n* Python 是**完全面向对象的语言**\n  * **函数**、**模块**、**数字**、**字符串**都是对象，**在 Python 中一切皆对象**\n  * 完全支持继承、重载、多重继承\n  * 支持重载运算符，也支持泛型设计\n* Python **拥有一个强大的标准库**，Python 语言的核心只包含 **数字**、**字符串**、**列表**、**字典**、**文件** 等常见类型和函数，而由 Python 标准库提供了 **系统管理**、**网络通信**、**文本处理**、**数据库接口**、**图形系统**、**XML 处理** 等额外的功能。\n* Python 社区提供了**大量的第三方模块**，使用方式与标准库类似。它们的功能覆盖 **科学计算**、**人工智能**、**机器学习**、**Web 开发**、**数据库接口**、**图形系统** 多个领域。\n\n## 1.3 Python 的优缺点\n\n- **优点**\n  - 简单、易学\n  - 免费、开源\n  - **面向对象**\n  - 丰富的库\n  - 可扩展性\n    - 如果需要一段关键代码运行得更快或者希望某些算法不公开，可以把这部分程序用 `C` 或 `C++` 编写，然后在 `Python` 程序中使用它们\n  - ……\n- **缺点**\n  - 运行速度\n  - 国内市场较小\n  - 中文资料匮乏\n\n# 2. Python 程序\n\n1. Python 源程序就是**一个特殊格式的文本文件**，可以**使用任意文本编辑软件**做 `Python` 的开发\n2. Python 程序的 **文件扩展名** 通常都是 `.py`\n\n**Tips:（报错提示）**\n\n- error 错误\n- name 名字\n- defined 已经定义\n- syntax 语法\n- invalid 无效\n- Indentation 索引\n- unexpected 意外的，不期望的\n- character 字符\n- line 行\n- encoding 编码\n- declared 声明\n- details 细节，详细信息\n- ASCII 一种字符编码\n\n# 3. `Python 2.x` 与 `3​​.x` 版本简介\n\n目前市场上有两个 Python 的版本并存着，分别是 `Python 2.x` 和 `Python 3.x`\n\n> 新的 Python 程序建议使用 `Python 3.0` 版本的语法\n\n* Python 2.x 是 **过去的版本**\n  * 解释器名称是 **python**\n* Python 3.x 是 **现在和未来 主流的版本**\n  * 解释器名称是 **python3**\n  * 相对于 `Python` 的早期版本，这是一个 **较大的升级**\n  * 为了不带入过多的累赘，`Python 3.0` 在设计的时候 **没有考虑向下兼容**\n    * 许多早期 `Python` 版本设计的程序都无法在 `Python 3.0` 上正常执行\n  * Python 3.0 发布于 **2008 年**\n  * 到目前为止，Python 3.0 的稳定版本已经有很多年了\n    * Python 3.3 发布于 2012\n    * Python 3.4 发布于 2014\n    * Python 3.5 发布于 2015\n    * Python 3.6 发布于 2016\n* 为了照顾现有的程序，官方提供了一个过渡版本 —— **Python 2.6**\n  * 基本使用了 `Python 2.x` 的语法和库\n  * 同时考虑了向 `Python 3.0` 的迁移，**允许使用部分** `Python 3.0` 的语法与函数\n  * 2010 年中推出的 `Python 2.7` 被确定为 **最后一个Python 2.x 版本**\n\n> 提示：如果开发时，无法立即使用 Python 3.0（还有极少的第三方库不支持 3.0 的语法），建议\n>\n> * 先使用 `Python 3.0` 版本进行开发\n> * 然后使用 `Python 2.6`、`Python 2.7` 来执行，并且做一些兼容性的处理\n\n# 4. 执行 Python 程序的三种方式\n\n## 4.1  解释器 `python` / `python3`\n\n### 1) Python 的解释器\n\n```bash\n# 使用 python 2.x 解释器\n$ python xxx.py\n\n# 使用 python 3.x 解释器\n$ python3 xxx.py\n```\n\n### 2) 其他解释器\n\n**Python 的解释器** 如今有多个语言的实现，包括：\n\n- `CPython` —— 官方版本的 C 语言实现\n- `Jython` —— 可以运行在 Java 平台\n- `IronPython` —— 可以运行在 .NET 和 Mono 平台\n- `PyPy` —— Python 实现的，支持 JIT 即时编译\n\n## 4.2 交互式运行 Python 程序\n\n- 直接在终端中运行解释器，而不输入要执行的文件名\n- 在 Python 的 `Shell` 中直接输入 **Python 的代码**，会立即看到程序执行结果\n\n### 1) 交互式运行 Python 的优缺点\n\n- **优点**\n  - 适合于学习/验证 Python 语法或者局部代码\n- **缺点**\n  - 代码不能保存\n  - 不适合运行太大的程序\n\n### 2) 退出 官方的解释器\n\n- 1> 直接输入 `exit()`\n\n```python\n>>> exit()\n```\n\n- 2> 使用热键退出\n  在 python 解释器中，按热键 `ctrl + d` 可以退出解释器\n\n### 3) IPython\n\n- IPython 中 的 “I” 代表 **交互 interactive**\n\n**特点**\n\n- IPython 是一个 python 的 **交互式 shell**，比默认的 `python shell` 好用得多\n  - 支持自动补全\n  - 自动缩进\n  - 支持 `bash shell` 命令\n  - 内置了许多很有用的功能和函数\n- IPython 是基于 BSD 开源的\n\n**版本**\n\n- Python 2.x 使用的解释器是 **ipython**\n- Python 3.x 使用的解释器是 **ipython3**\n\n**要退出解释器可以有以下两种方式：**\n\n- 1> 直接输入 `exit`\n\n```python\nIn [1]: exit\n```\n\n- 2> 使用热键退出\n  在 IPython 解释器中，按热键 `ctrl + d`，`IPython` 会询问是否退出解释器\n\n## 4.3. Python 的 IDE —— `PyCharm`\n\n### 1） 集成开发环境（IDE）\n\n集成开发环境（`IDE`，Integrated Development Environment）—— **集成了开发软件需要的所有工具**，一般包括以下工具：\n\n- 图形用户界面\n- 代码编辑器（支持 **代码补全**／**自动缩进**）\n- 编译器／解释器\n- 调试器（**断点**／**单步执行**）\n- ……\n\n### 2）PyCharm 介绍\n\n- `PyCharm` 是 Python 的一款非常优秀的集成开发环境\n- `PyCharm` 除了具有一般 IDE 所必备功能外，还可以在 `Windows`、`Linux`、`macOS` 下使用\n- `PyCharm` 适合开发大型项目\n  - 一个项目通常会包含 **很多源文件**\n  - 每个 **源文件** 的代码行数是有限的，通常在几百行之内\n  - 每个 **源文件** 各司其职，共同完成复杂的业务功能","tags":["开发语言"],"categories":["Python"]},{"title":"Perceptron","url":"/article/Perceptron.html","content":"\n\n# 1 感知器模型\n## 1.1 起源\n感知器模型与算法由美国科学家 Frank Rosenblatt 于 1958 年提出，最早用于解决图像分类问题。我们把向量 $ \\begin{equation} x = (x_1, x_2, ... , x_n)^T \\end{equation} $ 称为模式（Pattern）或特征（Feature）向量，比如 $ \\begin{equation} x_i \\end{equation} $ 表示图像中第 i 个像素的亮度。标量 y 称为类别标号（Class label）。感知器可以把一个模式 x 区分为两个不同的类别 $ \\begin{equation} (y = -1, +1) \\end{equation} $ ，这个过程称为分类（Classification）。\n\n## 1.2 定义\n假设输入空间（特征空间）是 $ \\begin{equation} \\mathcal{X} \\in R^n \\end{equation} $ ，输出空间是 $ \\begin{equation} \\mathcal{Y} \\in \\lbrace -1, 1 \\rbrace \\end{equation} $ ，其中输入 $ \\begin{equation} x \\in \\mathcal{X} \\end{equation} $ 表示实例的特征向量，对应于输入空间（特征空间）的点，输出 $ \\begin{equation} y \\in \\mathcal{Y} \\end{equation} $ 表示实例的类别，有输入空间到输出空间的函数：\n$$ \\begin{equation} \ng(x; w, b) = sgn(w^Tx + b) \n\\end{equation} $$\n称为感知器。其中 **g** 称为决策函数，**sgn** 称为符号函数：\n$$ \\begin{equation} \nsgn(x) = \n\\begin{cases}\n\\ \\ \\ 1, &x \\geqslant 0\\\\\n-1, &x < 0\n\\end{cases}\n\\end{equation} $$\n由判别函数得到一个方程：\n$$ \\begin{equation} \n\\mathcal{f} (x; w, b) = w^Tx + b = 0\n\\end{equation} $$\n该方程是一个线性方程，表示 d 维空间的一个超平面（hyper-plane），称为决策面（Decision Boundary），把该空间划分两半，位于该决策面一侧的样本 **x** 为正样本（**y** = 1）、位于另一侧的样本为负样本（**y**  = -1），**w** 为该超平面的法向量，**b** 为位置偏置。图 1 展示了 d = 2 时的情况。\n![图1 线性决策面](Perceptron/图1_线性决策面.jpg)\n<center><p>图1 线性决策面</p></center>\n由于 d 维感知器的决策面是一个超平面，因此一个感知器只能对可以用超平面分隔的样本进行区分，如果样本的分布不能用线性超平面区分（线性不可分），那么单个感知器就无法起作用。比如图 2 中的红色与蓝色样本，是线性不可分的。\n![图2 线性不可分](Perceptron/图2_线性不可分.jpg)\n\n<center><p>图2 线性不可分</p></center>\n\n\n# 2 感知器学习算法\n\n## 2.1 定义\n感知器模型由参数 $ \\begin{equation} \\Theta  = (w, b ) \\end{equation} $ 决定。但是在很多问题中，这些参数无法由人工决定。比如，图像分类中，权值 $ \\begin{equation} w_i \\end{equation} $ 表示第i个像素的权值，这个权值很难由人工分析确定。因此需要有一种方法能自动确定这些参数。在机器学习中，如果给定一组已知类别标号的样本集 $ \\begin{equation} D = \\lbrace (x^{(i)}, y^{(i)}) \\rbrace (i = 1, 2, ..., n) \\end{equation} $ ，那么可以从这组样本中学习（Learning）/训练（Training）出模型的参数 $ \\begin{equation} \\Theta \\end{equation} $ 。\n**感知器学习算法**（Perceptron Learning Algorithm，PLA）是 Rosenblatt 给出的一个用于学习感知器模型的算法。该算法是一个迭代算法，首先初化模型参数为 **w** = 0，**b** = 0，假设第 t 步得到的模型参数为 $ \\begin{equation} \\Theta  = (w, b ) \\end{equation} $ ，在 t + 1 步，从 **D** 中选取一个样本 $ \\begin{equation} (x^{(j)}, y^{(j)}) \\end{equation} $ ，用当前模型参数代入感知器中对该样本进行分类，得到分类结果为 $ \\begin{equation} \\bar y \\end{equation} $ 。如果分类正确（ $ \\begin{equation} \\bar y = y^{(j)} \\end{equation} $ ），那么权值不变；如果分类错误（ $ \\begin{equation} \\bar y \\neq y^{(j)} \\end{equation} $ ），根据类别标号  $ \\begin{equation} y = y^{(j)} \\end{equation} $  对权值做如下更新：\n$$\\begin{equation}\\begin{split} \n&w \\leftarrow w + y^{(j)}x^{(j)} \\\\ \n&b \\leftarrow b + y^{(j)}\n\\end{split}\\end{equation}$$  \n\n## 2.2 PLA算法（伪代码）\n下面的伪代码展示了感知器的学习过程：  \n![PLA算法伪代码](Perceptron/PLA算法伪代码.jpg)\n当训练样本集D是线性可分时，上述算法在有限步内能输出一个能对D中所有样本正确分类的模型$ \\begin{equation} g(x; w, b) \\end{equation} $。  \n\n## 2.3 PLA算法实现\n1. 算法思想：对样本集进行**重复迭代**，以实现**逐点修正**。\n\t- ① 获取样本集中本次迭代的样本的预测值  $ \\begin{equation} \\bar y \\end{equation} $ 。\n\t- ② 将预测值 $ \\begin{equation} \\bar y \\end{equation} $ 和该样本的真实值 $ \\begin{equation} y^{(i)} \\end{equation} $ 进行比较。\n\t\t- 分类正确，对样本集中的下一个样本进行预测，即跳转到 ① 处执行，直至样本集中的样本全部迭代，然后跳转至③。\n\t\t- 分类错误，标记出现错误分类，然后对 $ \\begin{equation} \\vec w \\end{equation} $  和 **b** 进行更新，完成后跳转到 ① 处执行，直至样本集中的样本全部迭代，然后跳转至③。\n\t- ③ 若样本集中的所有样本全部迭代，且**未出现错误分类**，即说明当前的权重和偏差值正确，输出此时的 $ \\begin{equation} \\vec w \\end{equation} $  和 **b** 。\n2. Java实现：\n\n- PLA算法核心\n```Java\n// 重复迭代样本集实现逐点修正\nwhile (true){\n    boolean flag = true;    // 错误分类标记（用于判断当前w、b是否可以实现二分类）\n    Collections.shuffle(data);  // 对测试集进行随机排序\n    for (Data d : data) {   // 迭代样本集\n        int y_hat = forecast(weight, b, d); // 预测值\n        int y = d.getY();   // 真实值\n        if (y * y_hat <= 0){  // 判断当前分类是否正确，>0正确\n            flag = false;   // 出现错误分类\n            weight = update(weight, d); // 更新权重\n            b += d.getY();  // 更新偏差值\n        }\n    }\n    if (flag)\t// 本次迭代未出现错误分类\n        break;\n}\n```\n\n- forecast(Weight weight, int b, Data data)方法\n```Java\n/**\n * 计算y_hat(预测值)\n * @param weight    权重\n * @param b         偏差值\n * @param data      数据集\n * @return          返回预测值\n */\npublic static int forecast(Weight weight, int b, Data data){\n    return ((weight.getW1() * data.getX1()) + (weight.getW2() * data.getX2()) + b);\n}\n\n```\n\n- update(Weight weight, Data data)方法\n```Java\n/**\n * 更新权重\n * @param weight    原权重值\n * @param data      数据集\n * @return          返回更新后的权重\n */\npublic static Weight update(Weight weight, Data data){\n    // 获取样本数据\n    int x1 = data.getX1();\n    int x2 = data.getX2();\n\n    // 获取实际值\n    int y = data.getY();\n\n    // 更新权重\n    int newW1 = weight.getW1() + (y * x1);\n    int newW2 = weight.getW2() + (y * x2);\n    weight.setW1(newW1);\n    weight.setW2(newW2);\n    return weight;\n}\n```\n\n- 运行结果\n\n（1）运行结果1  \n![运行结果1](Perceptron/PLA（java实现）运行结果1.jpg)\n\n（2）运行结果2\n![运行结果2](Perceptron/PLA（java实现）运行结果2.jpg)\n\n（3）运行结果3\n![运行结果3](Perceptron/PLA（java实现）运行结果3.jpg)\n\n（4）运行结果4\n![运行结果4](Perceptron/PLA（java实现）运行结果4.jpg)\n\n# 3 总结\n\n- 感知器主要可以解决线性可分的问题，他可以用来解决**二分类问题**，其具有如下的优点和缺点：\n\t- 优点：相较于其他模型，感知器模型简单，易于实现。\n\t- 缺点：\n\t\t- PLA算法每一次运行的结果不一致（不稳定），所以无法完美的处理线性不可分的训练集（数据）。\n\t\t- 感知机中的损失函数（衡量预测值与真实值之间的误差）的目标只是减小所有误分类点与超平面，最终很有可能导致部分样本点距离超平面很近。所以通过PLA得到的只是一个近似最优解的解，并不能得到最优解。\n- 导致PLA算法第一个缺点的主要原因是因为该算法的基本原理是**逐点修正**。首先，在超平面上随意取一条分类面，统计分类错误的点，然后随机对某个错误点进行修正，也就是改变直线的位置，使该错误点得以修正；接着再随机选一个错误点进行纠正，分类面不断变化，直到所有的点都完全分类正确了，就得到了最佳的分类面。正是因为每次运行PLA算法进行的是一种随机修正，所以得到的结果不一样。\n- PLA算法的第二个确定可以通过**SVM**（支持向量机）解决，另外SVM也可以很好地解决线性不可分问题。\n\n\n\n\n\n\n\n\n","tags":["ML（机器学习）","algorithm（算法）","Perceptron（感知器）","linear classification（线性分类）"],"categories":["AI（人工智能）"]}]